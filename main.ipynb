%%main.ipynb
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Channel Audio Feature Selection with Data Augmentation\n",
    "## STARSS23 Dataset with AST Transformer\n",
    "\n",
    "Includes spatial white noise, random filtering, and SpecAugment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchaudio librosa pandas numpy matplotlib seaborn scikit-learn pywavelets\n",
    "!pip install git+https://github.com/YuanGongND/ast\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from ast import ASTModel\n",
    "import random\n",
    "from scipy import signal\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"sample_rate\": 24000,\n",
    "    \"n_fft\": 1024,\n",
    "    \"hop_length\": 512,\n",
    "    \"n_freq_bins\": 513,\n",
    "    \"max_time_frames\": 500,\n",
    "    \"feature_combinations\": {\n",
    "        \"all\": [\"mag\", \"phase\", \"sin_ipd\", \"cos_ipd\"],\n",
    "        \"no_phase\": [\"mag\", \"sin_ipd\", \"cos_ipd\"],\n",
    "        \"no_ipd\": [\"mag\", \"phase\"],\n",
    "        \"mag_only\": [\"mag\"],\n",
    "        \"ipd_only\": [\"sin_ipd\", \"cos_ipd\"]\n",
    "    },\n",
    "    \"batch_size\": 8,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 50,\n",
    "    \"num_classes_sed\": 14,\n",
    "    \"num_classes_loc\": 2,\n",
    "    \"tetrahedral_pairs\": [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)],\n",
    "    \"augmentation\": {\n",
    "        \"spatial_noise_snr_range\": [15, 25],  # dB\n",
    "        \"random_filter_prob\": 0.3,\n",
    "        \"specaugment_prob\": 0.5,\n",
    "        \"time_mask_max_frames\": 50,\n",
    "        \"freq_mask_max_bins\": 30,\n",
    "        \"num_time_masks\": 2,\n",
    "        \"num_freq_masks\": 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourChannelAugmentation:\n",
    "    \"\"\"4-channel specific data augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def spatial_white_noise(self, audio, snr_db=None):\n",
    "        \"\"\"\n",
    "        Add spatially independent white noise to 4 channels\n",
    "        \n",
    "        Args:\n",
    "            audio: (4, samples) array\n",
    "            snr_db: Signal-to-noise ratio in dB\n",
    "        \"\"\"\n",
    "        if snr_db is None:\n",
    "            snr_db = np.random.uniform(*self.config['augmentation']['spatial_noise_snr_range'])\n",
    "        \n",
    "        augmented = np.zeros_like(audio)\n",
    "        \n",
    "        for ch in range(4):\n",
    "            # Calculate signal power\n",
    "            signal_power = np.mean(audio[ch]**2)\n",
    "            \n",
    "            # Calculate noise power based on SNR\n",
    "            noise_power = signal_power / (10**(snr_db/10))\n",
    "            \n",
    "            # Generate independent noise for each channel\n",
    "            noise = np.random.normal(0, np.sqrt(noise_power), audio.shape[1])\n",
    "            \n",
    "            # Add noise\n",
    "            augmented[ch] = audio[ch] + noise\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    def random_filter(self, audio):\n",
    "        \"\"\"\n",
    "        Apply random filtering to simulate room acoustics\n",
        "        Uses different filters for each channel to simulate spatial variation\n",
    "        \"\"\"\n",
    "        if np.random.random() > self.config['augmentation']['random_filter_prob']:\n",
    "            return audio\n",
    "        \n",
    "        augmented = np.zeros_like(audio)\n",
    "        \n",
    "        for ch in range(4):\n",
    "            # Random IIR filter parameters\n",
    "            filter_type = random.choice(['lowpass', 'highpass', 'bandpass'])\n",
    "            \n",
    "            if filter_type == 'lowpass':\n",
    "                cutoff = np.random.uniform(4000, 12000)\n",
    "                b, a = signal.butter(4, cutoff / (self.config['sample_rate']/2), 'low')\n",
    "            elif filter_type == 'highpass':\n",
    "                cutoff = np.random.uniform(100, 1000)\n",
    "                b, a = signal.butter(4, cutoff / (self.config['sample_rate']/2), 'high')\n",
    "            else:  # bandpass\n",
    "                lowcut = np.random.uniform(500, 3000)\n",
    "                highcut = np.random.uniform(4000, 10000)\n",
    "                b, a = signal.butter(4, [lowcut, highcut] / (self.config['sample_rate']/2), 'band')\n",
    "            \n",
    "            # Apply filter\n",
    "            augmented[ch] = signal.filtfilt(b, a, audio[ch])\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    def specaugment_time_freq_masking(self, features):\n",
    "        \"\"\"\n",
    "        Apply SpecAugment: time and frequency masking to feature matrix\n",
    "        \n",
    "        Args:\n",
    "            features: (n_features, time_frames) array\n",
    "        \"\"\"\n",
    "        if np.random.random() > self.config['augmentation']['specaugment_prob']:\n",
    "            return features\n",
    "        \n",
    "        augmented = features.copy()\n",
    "        n_features, n_time = augmented.shape\n",
    "        \n",
    "        # Time masking\n",
    "        for _ in range(self.config['augmentation']['num_time_masks']):\n",
    "            t_mask_width = np.random.randint(1, self.config['augmentation']['time_mask_max_frames'] + 1)\n",
    "            t_start = np.random.randint(0, n_time - t_mask_width)\n",
    "            augmented[:, t_start:t_start + t_mask_width] = 0\n",
    "        \n",
    "        # Frequency masking\n",
    "        for _ in range(self.config['augmentation']['num_freq_masks']):\n",
    "            f_mask_width = np.random.randint(1, self.config['augmentation']['freq_mask_max_bins'] + 1)\n",
    "            f_start = np.random.randint(0, n_features - f_mask_width)\n",
    "            augmented[f_start:f_start + f_mask_width, :] = 0\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    def apply_augmentations(self, audio, features, apply_audio_aug=True, apply_spec_aug=True):\n",
    "        \"\"\"Apply all augmentations\"\"\"\n",
    "        augmented_audio = audio.copy()\n",
    "        augmented_features = features.copy()\n",
    "        \n",
    "        if apply_audio_aug:\n",
    "            # Apply spatial white noise\n",
    "            augmented_audio = self.spatial_white_noise(augmented_audio)\n",
    "            \n",
    "            # Apply random filtering\n",
    "            augmented_audio = self.random_filter(augmented_audio)\n",
    "        \n",
    "        if apply_spec_aug:\n",
    "            # Apply SpecAugment to features\n",
    "            augmented_features = self.specaugment_time_freq_masking(augmented_features)\n",
    "        \n",
    "        return augmented_audio, augmented_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_4ch_features(audio, feature_types, sr=24000):\n",
    "    \"\"\"\n",
    "    Extract features from 4-channel audio array\n",
    "    \n",
    "    Args:\n",
    "        audio: (4, samples) array\n",
    "        feature_types: List of features to include\n",
    "        sr: Sample rate\n",
    "    \n",
    "    Returns:\n",
    "        Feature matrix\n",
    "    \"\"\"\n",
    "    # STFT parameters\n",
    "    n_fft = CONFIG['n_fft']\n",
    "    hop_length = CONFIG['hop_length']\n",
    "    n_freq_bins = CONFIG['n_freq_bins']\n",
    "    max_time_frames = CONFIG['max_time_frames']\n",
    "    \n",
    "    # Compute STFT for each channel\n",
    "    stfts = [librosa.stft(channel, n_fft=n_fft, hop_length=hop_length) \n",
    "             for channel in audio]\n",
    "    \n",
    "    # Extract magnitude and phase\n",
    "    magnitudes = [np.abs(stft) for stft in stfts]\n",
    "    phases = [np.angle(stft) for stft in stfts]\n",
    "    \n",
    "    # Compute IPD features for tetrahedral pairs\n",
    "    sin_ipds = []\n",
    "    cos_ipds = []\n",
    "    \n",
    "    for i, j in CONFIG['tetrahedral_pairs']:\n",
    "        phase_diff = phases[j] - phases[i]\n",
    "        sin_ipds.append(np.sin(phase_diff))\n",
    "        cos_ipds.append(np.cos(phase_diff))\n",
    "    \n",
    "    # Collect selected features\n",
    "    feature_components = []\n",
    "    \n",
    "    if 'mag' in feature_types:\n",
    "        feature_components.extend(magnitudes)\n",
    "    if 'phase' in feature_types:\n",
    "        feature_components.extend(phases)\n",
    "    if 'sin_ipd' in feature_types:\n",
    "        feature_components.extend(sin_ipds)\n",
    "    if 'cos_ipd' in feature_types:\n",
    "        feature_components.extend(cos_ipds)\n",
    "    \n",
    "    # Stack features\n",
    "    feature_matrix = np.vstack(feature_components)\n",
    "    \n",
    "    # Truncate or pad time dimension\n",
    "    if feature_matrix.shape[1] < max_time_frames:\n",
    "        pad_width = max_time_frames - feature_matrix.shape[1]\n",
    "        feature_matrix = np.pad(feature_matrix, ((0, 0), (0, pad_width)), \n",
    "                               mode='constant')\n",
    "    else:\n",
    "        feature_matrix = feature_matrix[:, :max_time_frames]\n",
    "    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STARSS23Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"STARSS23 dataset with on-the-fly augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata, feature_types, augment=True, mode='train'):\n",
    "        self.metadata = metadata\n",
    "        self.feature_types = feature_types\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.augmenter = FourChannelAugmentation(CONFIG)\n",
    "        \n",
    "        # Precompute feature dimensions\n",
    "        self.n_features = 0\n",
    "        if 'mag' in feature_types:\n",
    "            self.n_features += 4  # 4 channels\n",
    "        if 'phase' in feature_types:\n",
    "            self.n_features += 4\n",
    "        if 'sin_ipd' in feature_types:\n",
    "            self.n_features += 6  # 6 pairs\n",
    "        if 'cos_ipd' in feature_types:\n",
    "            self.n_features += 6\n",
    "        \n",
    "        self.n_features *= CONFIG['n_freq_bins']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        audio_path = row['file']\n",
    "        \n",
    "        # Load 4-channel audio\n",
    "        audio, orig_sr = sf.read(audio_path)\n",
    "        audio = audio.T  # Transpose to (channels, samples)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if orig_sr != CONFIG['sample_rate']:\n",
    "            audio_resampled = []\n",
    "            for channel in audio:\n",
    "                audio_resampled.append(librosa.resample(channel, orig_sr=orig_sr, \n",
    "                                                      target_sr=CONFIG['sample_rate']))\n",
    "            audio = np.array(audio_resampled)\n",
    "        \n",
    "        # Ensure exactly 4 channels\n",
    "        audio = audio[:4]\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_4ch_features(audio, self.feature_types, CONFIG['sample_rate'])\n",
    "        \n",
    "        # Apply augmentations during training\n",
    "        if self.augment and self.mode == 'train':\n",
    "            # Apply audio-level augmentations and re-extract features\n",
    "            audio_aug, _ = self.augmenter.apply_augmentations(audio, features, \n",
    "                                                            apply_audio_aug=True, \n",
    "                                                            apply_spec_aug=False)\n",
    "            features = extract_4ch_features(audio_aug, self.feature_types, CONFIG['sample_rate'])\n",
    "            \n",
    "            # Apply SpecAugment to features\n",
    "            features = self.augmenter.specaugment_time_freq_masking(features)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "        sed_labels_tensor = torch.tensor(row['sed_labels'], dtype=torch.float32)\n",
    "        loc_labels_tensor = torch.tensor(row['loc_labels'], dtype=torch.float32)\n",
    "        \n",
    "        return features_tensor, sed_labels_tensor, loc_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_starss23_metadata(data_dir):\n",
    "    \"\"\"Load STARSS23 metadata\"\"\"\n",
    "    metadata = {\n",
    "        'file': [],\n",
    "        'sed_labels': [],\n",
    "        'loc_labels': []\n",
    "    }\n",
    "    \n",
    "    # Traverse dataset directory\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                # Get corresponding annotation file\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                ann_path = os.path.join(root, f\"{base_name}.csv\")\n",
    "                \n",
    "                if not os.path.exists(ann_path):\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Parse annotations\n",
    "                    ann_df = pd.read_csv(ann_path, header=None)\n",
    "                    ann_df.columns = ['start', 'end', 'azimuth', 'elevation', 'class']\n",
    "                    \n",
    "                    # Aggregate labels\n",
    "                    class_counts = ann_df['class'].value_counts()\n",
    "                    majority_class = class_counts.idxmax()\n",
    "                    \n",
    "                    # Convert to one-hot encoding\n",
    "                    sed_label = np.zeros(CONFIG['num_classes_sed'])\n",
    "                    sed_label[majority_class] = 1\n",
    "                    \n",
    "                    # Average location\n",
    "                    avg_azimuth = ann_df['azimuth'].mean()\n",
    "                    avg_elevation = ann_df['elevation'].mean()\n",
    "                    \n",
    "                    metadata['file'].append(os.path.join(root, file))\n",
    "                    metadata['sed_labels'].append(sed_label)\n",
    "                    metadata['loc_labels'].append([avg_azimuth, avg_elevation])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {ann_path}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetraAST(nn.Module):\n",
    "    \"\"\"AST model for 4-channel input\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes_sed, num_classes_loc):\n",
    "        super().__init__()\n",
    "        \n",
    "        # AST backbone\n",
    "        self.ast = ASTModel(\n",
    "            input_tdim=input_dim[1],\n",
    "            input_fdim=input_dim[0],\n",
    "            label_dim=num_classes_sed,\n",
    "            imagenet_pretrain=False,\n",
    "            audioset_pretrain=True\n",
    "        )\n",
    "        \n",
    "        ast_output_dim = 768\n",
    "        \n",
    "        # SED classifier\n",
    "        self.sed_head = nn.Sequential(\n",
    "            nn.LayerNorm(ast_output_dim),\n",
    "            nn.Linear(ast_output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes_sed)\n",
    "        )\n",
    "        \n",
    "        # Source localization head\n",
    "        self.loc_head = nn.Sequential(\n",
    "            nn.LayerNorm(ast_output_dim),\n",
    "            nn.Linear(ast_output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes_loc)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # AST forward pass\n",
    "        x = self.ast(x)\n",
    "        \n",
    "        # SED classification\n",
    "        sed_logits = self.sed_head(x)\n",
    "        \n",
    "        # Source localization\n",
    "        loc_output = self.loc_head(x)\n",
    "        \n",
    "        return sed_logits, loc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_augmentation(metadata, feature_combo):\n",
    "    \"\"\"Train model with data augmentation\"\"\"\n",
    "    # Split metadata\n",
    "    train_meta, test_meta = train_test_split(metadata, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = STARSS23Dataset(train_meta, CONFIG['feature_combinations'][feature_combo], \n",
    "                                  augment=True, mode='train')\n",
    "    test_dataset = STARSS23Dataset(test_meta, CONFIG['feature_combinations'][feature_combo], \n",
    "                                 augment=False, mode='test')\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    input_dim = (train_dataset.n_features, CONFIG['max_time_frames'])\n",
    "    model = TetraAST(input_dim, CONFIG['num_classes_sed'], CONFIG['num_classes_loc'])\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # Loss functions and optimizer\n",
    "    sed_criterion = nn.BCEWithLogitsLoss()\n",
    "    loc_criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_f1 = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'sed_f1': [], 'loc_mae': []}\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (inputs, sed_targets, loc_targets) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                sed_targets = sed_targets.cuda()\n",
    "                loc_targets = loc_targets.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            sed_logits, loc_output = model(inputs)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sed_loss = sed_criterion(sed_logits, sed_targets)\n",
    "            loc_loss = loc_criterion(loc_output, loc_targets)\n",
    "            total_loss = sed_loss + 0.5 * loc_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += total_loss.item()\n",
    "            \n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f'  Batch {batch_idx}/{len(train_loader)}, Loss: {total_loss.item():.4f}')\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        sed_preds = []\n",
    "        loc_preds = []\n",
    "        sed_true = []\n",
    "        loc_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, sed_targets, loc_targets in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = inputs.cuda()\n",
    "                    sed_targets = sed_targets.cuda()\n",
    "                    loc_targets = loc_targets.cuda()\n",
    "                \n",
    "                sed_logits, loc_output = model(inputs)\n",
    "                \n",
    "                # Calculate loss\n",
    "                sed_loss = sed_criterion(sed_logits, sed_targets)\n",
    "                loc_loss = loc_criterion(loc_output, loc_targets)\n",
    "                total_loss = sed_loss + 0.5 * loc_loss\n",
    "                val_loss += total_loss.item()\n",
    "                \n",
    "                # Collect predictions\n",
    "                sed_preds.extend(torch.sigmoid(sed_logits).cpu().numpy())\n",
    "                loc_preds.extend(loc_output.cpu().numpy())\n",
    "                sed_true.extend(sed_targets.cpu().numpy())\n",
    "                loc_true.extend(loc_targets.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(test_loader)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sed_preds_bin = np.array(sed_preds) > 0.5\n",
    "        sed_report = classification_report(sed_true, sed_preds_bin, output_dict=True)\n",
    "        \n",
    "        loc_errors = np.abs(np.array(loc_true) - np.array(loc_preds))\n",
    "        azimuth_mae = np.mean(loc_errors[:, 0])\n",
    "        elevation_mae = np.mean(loc_errors[:, 1])\n",
    "        \n",
    "        current_f1 = sed_report['macro avg']['f1-score']\n",
    "        current_mae = (azimuth_mae + elevation_mae) / 2\n",
    "        \n",
    "        history['sed_f1'].append(current_f1)\n",
    "        history['loc_mae'].append(current_mae)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        if current_f1 > best_val_f1:\n",
    "            best_val_f1 = current_f1\n",
    "            torch.save(model.state_dict(), f\"best_model_{feature_combo}.pth\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "              f\"SED F1: {current_f1:.4f} | LOC MAE: {current_mae:.2f}Â° | \"\n",
    "              f\"LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(torch.load(f\"best_model_{feature_combo}.pth\"))\n",
    "    \n",
    "    # Final evaluation\n",
    "    sed_preds = []\n",
    "    loc_preds = []\n",
    "    sed_true = []\n",
    "    loc_true = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, sed_targets, loc_targets in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "            \n",
    "            sed_logits, loc_output = model(inputs)\n",
    "            \n",
    "            sed_preds.extend(torch.sigmoid(sed_logits).cpu().numpy())\n",
    "            loc_preds.extend(loc_output.cpu().numpy())\n",
    "            sed_true.extend(sed_targets.numpy())\n",
    "            loc_true.extend(loc_targets.numpy())\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    sed_preds_bin = np.array(sed_preds) > 0.5\n",
    "    sed_metrics = classification_report(\n",
    "        sed_true, sed_preds_bin,\n",
    "        target_names=[f'class_{i}' for i in range(CONFIG['num_classes_sed'])],\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    loc_errors = np.abs(np.array(loc_true) - np.array(loc_preds))\n",
    "    azimuth_mae = np.mean(loc_errors[:, 0])\n",
    "    elevation_mae = np.mean(loc_errors[:, 1])\n",
    "    \n",
    "    loc_metrics = {\n",
    "        'azimuth_mae': azimuth_mae,\n",
    "        'elevation_mae': elevation_mae,\n",
    "        'overall_mae': (azimuth_mae + elevation_mae) / 2\n",
    "    }\n",
    "    \n",
    "    return sed_metrics, loc_metrics, history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_augmented_ablation_study(data_dir):\n",
    "    \"\"\"Run ablation study with data augmentation\"\"\"\n",
    "    print(\"Loading STARSS23 metadata...\")\n",
    "    metadata = load_starss23_metadata(data_dir)\n",
    "    print(f\"Loaded {len(metadata)} audio files\")\n",
    "    \n",
    "    # Results storage\n",
    "    results = {'sed': {}, 'loc': {}}\n",
    "    \n",
    "    # Train and evaluate for each feature combination\n",
    "    for combo in CONFIG['feature_combinations']:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training with feature combination: {combo}\")\n",
    "        print(f\"Features: {CONFIG['feature_combinations'][combo]}\")\n",
    "        print(f\"With data augmentation: Spatial noise + Random filtering + SpecAugment\")\n",
    "        print(f\"{'='*80}\\n\")\n",
